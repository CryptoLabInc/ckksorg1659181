<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://cryptolabinc.github.io/ckksorg1659181/feed.xml" rel="self" type="application/atom+xml"/><link href="https://cryptolabinc.github.io/ckksorg1659181/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-22T14:18:56+00:00</updated><id>https://cryptolabinc.github.io/ckksorg1659181/feed.xml</id><title type="html">CKKS.org</title><subtitle></subtitle><entry><title type="html">Bootstrapping Discrete Data with CKKS</title><link href="https://cryptolabinc.github.io/ckksorg1659181/blog/2025/Jaehyung/" rel="alternate" type="text/html" title="Bootstrapping Discrete Data with CKKS"/><published>2025-05-09T15:12:00+00:00</published><updated>2025-05-09T15:12:00+00:00</updated><id>https://cryptolabinc.github.io/ckksorg1659181/blog/2025/Jaehyung</id><content type="html" xml:base="https://cryptolabinc.github.io/ckksorg1659181/blog/2025/Jaehyung/"><![CDATA[<ul> <li>Written by <a href="https://jaehyungkim0.github.io/">Jaehyung Kim</a> (Stanford University)</li> <li>Based on <a href="https://ia.cr/2024/1637">https://ia.cr/2024/1637</a></li> </ul> <p><em>TL;DR: Recently, a new paradigm called discrete CKKS, which picks the best aspects of CKKS and other exact schemes has been suggested. To be more specific, it uses CKKS (a.k.a. the approximate homomorphic scheme) to compute over discrete data. In this article, we discuss the recent discrete bootstrapping in <a href="https://ia.cr/2024/1637">BKSS24</a> specifically designed for discrete CKKS.</em></p> <hr/> <h2 id="discrete-ckks">Discrete CKKS</h2> <p>Recall that CKKS is defined over the complex plane $\mathbb{C}$. We consider a finite discrete subset $U$ of $\mathbb{C}$ such as \(\mathbb{Z}_t = \{0, 1, \ldots, t-1\}\) for some $t \in \mathbb{Z}$ or a set of complex $t$-th root of unity $\mu_t = {exp(2 \pi i m / t)}_{0 \leq m &lt; t}$. Instead of using the entire $\mathbb{C}$ as the message space, we may use the subset $U$ as long as $U$ is closed under some arithmetic operations (e.g. $+$, $\times$). For instance, if $U = \mu_t$, we may instantiate addition over $\mu_t$ via multiplication over $\mathbb{C}$. The picuture below describes a set $\mu_8$, where the lightblue circles denote that CKKS allows some errors to the representations of each root of unity.</p> <div class="row mt-3"> <div class="col-sm-7 mt-3 mt-md-0 mx-auto d-block"> <figure> <picture> <source class="responsive-img-srcset" srcset="/ckksorg1659181/assets/img/blog/250509_Jaehyung/1-480.webp 480w,/ckksorg1659181/assets/img/blog/250509_Jaehyung/1-800.webp 800w,/ckksorg1659181/assets/img/blog/250509_Jaehyung/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/ckksorg1659181/assets/img/blog/250509_Jaehyung/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Using a restricted message space $U$ gives us two powerful capabilities. One is <strong>interpolation</strong> which allows us to compute arbitrary functions. Recall that addition and multiplication over the entire complex plane only support approximations which can only evaluate certain (semi-)continuous functions. On the other hand, interpolation over finite number of points can evaluate any function. For instance, the Lagrange interpolation allows us to send $k+1$ distinct points on the complex plane to arbitrary $k+1$ points on the complex plane via a degree $k$ polynomial. As CKKS supports addition and multiplication over integers, it can evaluate any complex coefficient polynomials.</p> <p>The other capability is <strong>message-error separation</strong> which allows one to distinguish error from the message. For example, let $U = \mathbb{Z}_8$ and one of the entries of the decryption of a ciphertext be 3.97. If the ciphertext were a usual CKKS ciphertext encrypting any real number, then we would not be able figure out what the actual message is (e.g. 3.95, 3.98, … can be candidates). However, since we know that the error is significantly smaller than the gaps between the elements of $U$, we can recover the original message, i.e. $4 = Round(3.97)$.</p> <p>As computations proceed, the error continously grows. To reduce it, we use cleaning polynomials with vanishing derivatives. For instance, the bit cleaning polynomial $h_1(x) = 3x^2-2x^3$ satisfies $h_1(0)=0$, $h_1(1)=1$, and $h_1’(0)=h_1’(1)=0$, sending complex numbers close to $0$, $1$ to numbers even closer to $0$, $1$, respectively. In this regard, the cleaning homomorphically reduces the error, allowing infinite number of operations without a contamination of the messages by the errors.</p> <h2 id="ckks-bootstrapping-reminders">CKKS bootstrapping reminders</h2> <p>When multiplying two CKKS ciphertexts with a scaling factor $\Delta$, the resulting ciphertext has a scaling factor $\Delta^2$. In order to reduce the scaling factor back to $\Delta$, we <strong>rescale</strong> by $q \approx \Delta$ for some $q$ that divides the ciphertext modulus. This is a necessary step that prevents the scaling factors from growing exponentially, but it consumes some ciphertext modulus per every multiplication. The <strong>CKKS bootstrapping</strong> is a homomorphic operation that recovers the ciphertext modulus.</p> <p>The key idea of the CKKS bootstrapping is very simple. If we raise the ciphertext modulus by simply embedding a small modulus $q_0$ into a larger modulus $Q$, a small multiple of $q_0$ is added to the plaintext. In other words, if the initial ciphertext encrypts a plaintext $m$, then the resulting ciphertext encrypts $m + q_0 \cdot I$ for some small integral $I$. In order to remove the $I$ term, we regard the new scaling factor as $q_0$ and homomorphically evaluate a modulo-$1$ function.</p> <p>A <a href="https://eprint.iacr.org/2018/153">common approach</a> for CKKS bootstrapping is to use trigonometric functions to approximate modular reduction. As long as $m$ is sufficiently smaller than $q_0$, the (scaled) trigonometric sine function $sin(2 \pi x) / (2 \pi)$ successfully removes $I$ while preserving $m$, as $sin(x) \approx x$ for small $x$. A sine function with a small number of periods can be efficiently approximated by well-known techniques such as the minimax polynomial from the Remez algorithm(s).</p> <h2 id="discrete-bootstrapping">Discrete bootstrapping</h2> <p>Although we can use any CKKS bootstrapping as a black box to bootstrap a discrete CKKS ciphertext, it is an interesting question whether there exists a more efficient, dedicated bootstrapping for discrete encoding. It turns out that there exists such a variant which not only efficiently bootstraps discrete data but also evaluates an arbitrary function as in functional/programmable bootstrapping in the context of CGGI/DM.</p> <p>We first recall the scheme conversion in <a href="https://eprint.iacr.org/2018/758">Chimera</a> which evaluates a complex exponential function to convert a low-level RLWE ciphertext into a high-level CKKS ciphertext. That is, given a modulus-raised ciphertext encrypting $m + q_0 \cdot I$, we evaluate $x \mapsto exp(2 \pi i x)$ which gives us $exp(2 \pi i m /q_0)$ while removing the $I$ part. In the discrete bootstrapping framework, we use this as a subroutine to achieve bootstrapping. An interesting observation is that the complex exponential function sends the equispaced points on the real line (i.e. $\mathbb{Z}_t$) to the equispaced points on the unit circle (i.e. $\mu_t$).</p> <p>Although any finite set of points provides interpolation, the set of complex roots of unity is a good candidate because its interpolation is numerically more stable than other alternatives, as illustrated in <a href="https://eprint.iacr.org/2024/274">CKKL24</a>. Given an arbitrary function from $\mathbb{Z}_t$ to $\mathbb{Z}_t$, we may translate such function as an interpolation from complex $t$-th roots of unity to $\mathbb{Z}_t$, allowing us to evaluate arbitrary look-up tables.</p> <p>The combination of the complex exponential in the first step and the interpolation in the second step gives us a CKKS bootstrapping for discrete data (i.e. raising modulus) plus evaluating an arbitrary function $: \mathbb{Z}_t \rightarrow \mathbb{Z}_t$.</p> <h2 id="implications">Implications</h2> <p>The discrete CKKS framework has been introduced in <a href="https://eprint.iacr.org/2022/1298">BLEACH</a>, and the discrete bootstrapping in <a href="https://eprint.iacr.org/2024/1637">BKSS24</a> further improves the framework by using bootstrapping in a non-black-box manner. In particular, the discrete bootstrapping suggests that one had better integrate bootstrapping and look-up table evaluation, and the rest of the moduli can be reserved for arithmetic operations (i.e. addition and multiplication) if needed.</p> <p>In terms of functionality, the discrete variant of CKKS extends the capability of CKKS to support arbitrary, possibly discontinuous functions. Compared to other exact schemes, CKKS had been struggling to support such feature due to the nature of polynomial approximations. The discrete bootstrapping provides a perfect solution to the problem of arbitrary function evaluation, while achieving similar asymptotic complexity as other schemes. Recall that BGV/BFV evaluates an arbitrary function as an interpolation over non-zero characeteristic fields, whose efficiency should be almost the same as interpolation over the complex plane.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/ckksorg1659181/assets/img/blog/250509_Jaehyung/2-480.webp 480w,/ckksorg1659181/assets/img/blog/250509_Jaehyung/2-800.webp 800w,/ckksorg1659181/assets/img/blog/250509_Jaehyung/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/ckksorg1659181/assets/img/blog/250509_Jaehyung/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In terms of concrete efficiency, the discrete bootstrapping can be interpreted as a parallelization of CGGI/DM functional bootstrapping (i.e. bootstrapping an LWE ciphertext while evaluating an arbitrary function). The experiments in BKKS24 show that this new approach is several orders of magnitude faster than CGGI/DM in terms of throughput, as illustrated above. When there is a moderate number of ciphertexts (e.g. 100), the CKKS-style functional bootstrapping (i.e. discrete bootstrapping) already outperforms CGGI/DM. Note that the functional bootstrapping is a key building block of CGGI/DM that is used to evaluate any circuit. In this regard, the CKKS-style functional bootstrapping can be viewed as an accelerator for CGGI/DM computations.</p> <p>In terms of security, discrete CKKS provides a solution for achieving advanced security notions (e.g. <a href="https://eprint.iacr.org/2020/1533">IND-CPA-D</a>) without going through expensive (direct) noise flooding. Recall that the only known solution for CKKS to achieve such security notions is to work with high precision for the whole circuit evaluation and to add huge noise at the end. As discrete CKKS is an exact scheme, it can use the same strategies as other exact schemes, providing a much more efficient option.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[TL;DR: Recently, a new paradigm called discrete CKKS, which picks the best aspects of CKKS and other exact schemes has been suggested. To be more specific, it uses CKKS (a.k.a. the approximate homomorphic scheme) to compute over discrete data. In this article, we discuss the recent discrete bootstrapping in BKSS24 specifically designed for discrete CKKS.]]></summary></entry><entry><title type="html">Grafting: Improving Performance and Usability of Homomorphic Encryption</title><link href="https://cryptolabinc.github.io/ckksorg1659181/blog/2025/Johannes/" rel="alternate" type="text/html" title="Grafting: Improving Performance and Usability of Homomorphic Encryption"/><published>2025-05-08T15:12:00+00:00</published><updated>2025-05-08T15:12:00+00:00</updated><id>https://cryptolabinc.github.io/ckksorg1659181/blog/2025/Johannes</id><content type="html" xml:base="https://cryptolabinc.github.io/ckksorg1659181/blog/2025/Johannes/"><![CDATA[<ul> <li>Written by <a href="https://www.asdf.one/">Johannes Mono</a> (Ruhr University Bochum &amp; CryptoLab)</li> <li>Based on <a href="https://ia.cr/2024/1014">https://ia.cr/2024/1014</a></li> </ul> <p><em>TL;DR: Grafting is a new approach for managing a CKKS ciphertext modulus. With so-called sprouts, we dedicate a few machine words to scaling and use word-sized primes for the remaining ciphertext modulus improving performance. With universal sprouts, we can represent any bit size up to the word size using powers-of-two and introduce arbitrary scaling for RNS-CKKS improving usability for parameter and circuit design.</em></p> <hr/> <p>Homomorphic encryption is one of the most exciting technologies for modern society. If you’ve never heard of it, congratulations, you’re one of <a href="https://xkcd.com/1053">today’s lucky 10,000</a>! Here’s our FAQ to get you started:</p> <ul> <li>What is homomorphic encryption?</li> <li>What is CKKS?</li> </ul> <p>In recent years, research has continuously improved two significant challenges: performance and usability. <em>Grafting</em> is a new technique improving performance and usability for the homomorphic encryption scheme CKKS. Let’s try to understand the problems Grafting solves.</p> <h2 id="ckks-parameters">CKKS Parameters</h2> <p>Encryption schemes base their security on mathematically hard problems. The CKKS scheme bases it on the Learning with Errors over Rings (RLWE) problem. Sounds complicated? It is. Fortunately, we do not need to understand it, we only need to meet one important RLWE parameter: the number $q$, also called <em>ciphertext modulus</em>. CKKS needs a huge ciphertext modulus, it sometimes uses over 3000 bits! For comparison, we can store the number of atoms in the universe in only 266 bits. And a single CKKS encryption needs thousands of random numbers from 0 to $q$. That sounds like lots of bits (and it is), but modern technology actually handles them with ease; even your smartphone can store many CKKS encryptions. Obviously, there is a catch. We use CKKS not only to store, but to compute on encryptions. And computing on thousands of numbers from 0 to $q$ is not cheap, especially because we compute complex mathematical functions.</p> <p>Despite its costs, CKKS is <a href="https://www.youtube.com/watch?v=Zl1lVxQyj60">reasonably fast on modern machines</a>. Modern machines operate on 64 bits at once, a so-called machine word. We want to use as few words as possible for our random numbers: the less words we compute on, the faster we are. For performance, we split up $q$ into $\ell$ small numbers, each using 64 bits:</p> \[\textstyle q = q_1 \cdot q_2 \cdot q_3 \cdot \ldots \cdot q_\ell = \prod_{i = 1}^\ell q_i \text{.}\] <p>Each number from 0 to $q$ corresponds to exactly $\ell$ numbers from 0 to $q_i$, one for each $q_i$ (Figure 1).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/ckksorg1659181/assets/img/blog/250508_Johannes/1-480.webp 480w,/ckksorg1659181/assets/img/blog/250508_Johannes/1-800.webp 800w,/ckksorg1659181/assets/img/blog/250508_Johannes/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/ckksorg1659181/assets/img/blog/250508_Johannes/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 1: A ciphertext modulus $q$ split up into $\ell = 10$ small numbers, each using 64 bits. </div> <p>This concept is also known as residue number system (RNS) and we can switch between one large number (0 to $q$) and $\ell$ small numbers (0 to $q_i$) anytime we want due to the <a href="https://en.m.wikipedia.org/wiki/Chinese_remainder_theorem">Chinese Remainder Theorem</a>. As with RLWE: We do not need to understand the math behind the RNS to understand Grafting, only what we use it for in CKKS. CKKS uses the RNS to improve performance, but it also uses it for the so-called scaling.</p> <h2 id="ckks-scaling">CKKS Scaling</h2> <p>CKKS encrypts approximate numbers which are, well, approximations of real numbers. An example you are probably familiar with is $\pi$: Teachers often approximate it as 3.14 for calculations even though it has infinitely many digits. In CKKS, we approximate numbers using integers and a scaling factor. For $3.14$, we need a scaling factor $\Delta = 100$ to store it in an integer:</p> \[3.14 \cdot s = 3.14 \cdot 100 = 314 \text{.}\] <p>For $3.14159265$, we need $\Delta = 100,000,000 = 10^8$:</p> \[3.14159265 \cdot \Delta = 3.14159265 \cdot 10^8 = 314159265 \text{.}\] <p>Alternatively, we round the scaled value and accept a worse approximation (for example with $s = 100$):</p> \[\lceil 3.14159265 \cdot \Delta\rfloor = \lceil 314.159265 \rfloor = 314 \text{.}\] <p>The larger the scaling factor, the better our approximation—but the larger our integers and the CKKS parameters we will need to encrypt them. We can add two scaled numbers $x$ and $y$ and get their scaled sum:</p> \[(\Delta \cdot x) + (\Delta \cdot y) = \Delta \cdot (x + y) \text{.}\] <p>We can also multiply two scaled numbers</p> \[(\Delta \cdot x) \cdot (\Delta \cdot y) = \Delta \cdot (\Delta \cdot x \cdot y) \text{;}\] <p>however, now we get an additional factor $\Delta$ which we have to remove again. For unencrypted numbers, we simply divide by $\Delta$ to get the correct result. For encrypted numbers, it is not that simple.</p> <p>Division in CKKS uses polynomial approximation, polynomial approximation needs multiplications, multiplications need divisions, divisions need polynomial approximations, polynomial approximations need … I think you understand the problem. Fortunately, we have a trick up our sleeves: Instead of dividing the encrypted numbers by $\Delta$, we remove one of the elements in $q = q_1 \cdot \ldots \cdot q_\ell$ with clever (and slightly complex) mathemathics. If $q_i \approx \Delta$, removing $q_i$ divides the encrypted numbers by $q_i \approx \Delta$ and we can remove the additional $\Delta$ from a multiplication! However, we cannot remove $q_i$ forever since $q$ only consists of $\ell$ small numbers. After $\ell - 1$ multiplications, we are left with only one small number: $q_1$. Then, we use a process called bootstrapping to go back to our big $q = q_1 \cdot \ldots \cdot q_\ell$.</p> <p>Scaling imposes another restriction on our $q_i$. Our accumulated requirements are now as follows:</p> <ul> <li>Each $q_i$ must be close to the scaling factor $s$ for multiplications to work correctly.</li> <li>Each $q_i$ needs to be a prime so we can use the RNS representation for performance.</li> <li>Each $q_i$ should use 64 bits (the machine word size) for best performance.</li> </ul> <p>But what if the scaling factor $s$ uses much less than 64 bits? Then, we waste computational resources: A modern machine always computes on 64 bits, even if we do not use all of them. And currently, CKKS scaling uses much less than 64 bits wasting precious resources. Grafting with universal sprouts solves this issue: We can scale by anything we want <em>and</em> choose large $q_i$ to use the full machine word.</p> <h2 id="grafting">Grafting</h2> <p>The idea behind Grafting is surprisingly simple. What if we could have one special 64 bit word where we can choose any bit size between 0 and 64? Then we could scale to any bit size we want. Example (Figure 2): We are at $330 = 10 + 5 \cdot 64$ bits and want to go to $300 = 44 + 4 * 64$ bits. We remove one large prime ($330 - 64 = 266$) and replace the special 30 bit word with a special 44 bit word ($266 - 10 + 44 = 300$).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/ckksorg1659181/assets/img/blog/250508_Johannes/2-480.webp 480w,/ckksorg1659181/assets/img/blog/250508_Johannes/2-800.webp 800w,/ckksorg1659181/assets/img/blog/250508_Johannes/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/ckksorg1659181/assets/img/blog/250508_Johannes/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Figure 2: Removing 30 bits from a ciphertext modulus without Grafting (top) and with Grafting (bottom). We need much less machine words for the same modulus size and still can easily scale by 30 bits. </div> <p>Along these lines, we can choose any bit size for $q$ using our special word. If we remove one bit from it, we scale the encrypted numbers by $s \approx 2$. Removing two bits from the special word scales the encrypted numbers by $s \approx 4$, removing three bits by $s \approx 8$, and so on. In some sense, we decouple the scaling that we need for a correct CKKS multiplications from the individual $q_i$. We call the special machine word a sprout, and we call it a universal sprout if it can have any bit size between 0 and 64. If you just came here to understand the idea behind Grafting, congratulations, you made it! That’s the idea, nothing more, nothing less.</p> <p>Of course, reality is more complex (it’s always the same, huh): How do we actually realize a universal sprout? While all the mathematical details are in <a href="https://eprint.iacr.org/2024/1014">our paper</a>, let’s try to understand it using much less math. Remember all the thousands of random numbers from 0 to $q$ I talked about? They have a specific meaning, they are coefficients of a polynomial with degree $N - 1$:</p> \[a(x) = a_0 + a_1 x + a_2 x^2 + \ldots + a_{N-1} x^{N-1} \text{;}\] <p>each coefficient $a_i$ is a number from 0 to $q$, each polynomial needs $N$ coefficients, and each ciphertext needs two of these polynomials. Sometimes, we need to multiply two polynomials and we multiply two polynomials with the so-called number theoretic transform (NTT). The <a href="https://en.wikipedia.org/wiki/Discrete_Fourier_transform_over_a_ring#Number-theoretic_transform">Wikipedia article</a> is not very helpful if you’re not a mathematician, so let’s stick to our approach: We only aim at understanding the consequences the NTT has for our $q_i$, not the math behind it. For the NTT, we need each $q_i$ to equal $1 \bmod 2 N$. If you’re not familiar with the modulo operation, don’t worry, I got you: The important thing for us is that it needs to be larger than $2 N$—and usually, $N$ is already 15–20 bits large. Hence, each $q_i$ is also at least 15–20 bits or larger. So how can we get a sprout to represent 0 to 20 bits?</p> <p>One approach is as follows: We use the powers-of-two $0, 1, 2, 4, 8, \ldots, 2^{20}$ even if we then cannot use the NTT. And we cannot, but we can employ another trick. We move the power-of-two polynomials to a polynomial with a helper prime, use the NTT for polynomial multiplication, then go back to the power-of-two. This works as long as the helper prime is larger than 60 bit which fortunately we have. That’s actually all we need, we have a universal sprout: We use powers-of-two for all bit sizes up to 20 with a helper prime, then use different primes up to 64 bit each. For $N = 2^{15}$, we reduce the number of $q_i$ from 20 to 12, so almost by 50%, and it results in up to two times better performance! But, in my personal opinion, that’s not the best part of Grafting. I’ve said it before, I’ll say it again: We decouple the scaling from the individual $q_i$ which makes CKKS much more usable. Two examples: Designing parameter sets is much easier now, and computing with arbitrary scalings is easier now. And that’s it! I hope you learned how Grafting improves the performance and usability of CKKS. 안녕히 가세요!</p> <h2 id="faq-what-is-homomorphic-encryption">FAQ: What is homomorphic encryption?</h2> <p>Homomorphic encryption is a special type of encryption which enables computations on encrypted data. You can think about it as locking bits or numbers in a secure box with buttons on the outside that launch operations such as an addition or multiplication. Homomorphic encryption enables new opportunities: You can encrypt your sensitive data, send it to a third party for expensive computations, and get back the encrypted result without doing any of these computations yourself. This is like sending the third party your secure box, telling them which buttons to press so you don’t have to do it, and afterward getting the box back with the result: Your information stays private even when being computed on.</p> <h2 id="faq-what-is-ckks">FAQ: What is CKKS?</h2> <p>CKKS is a homomorphic encryption scheme for approximate numbers. It was created by Cheon, Kim, Kim, and Song in 2016 and shines in data analysis and modelling. Real-world data is often approximate (for example measurements such as temperature) and so are the computations on the data (for example weather forecasting). CKKS trades off an exact result for better performance and is a great choice for encrypted computations on most real-world data.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[TL;DR: Grafting is a new approach for managing a CKKS ciphertext modulus. With so-called sprouts, we dedicate a few machine words to scaling and use word-sized primes for the remaining ciphertext modulus improving performance. With universal sprouts, we can represent any bit size up to the word size using powers-of-two and introduce arbitrary scaling for RNS-CKKS improving usability for parameter and circuit design.]]></summary></entry></feed>