---
layout: post
title: >
  Grafting: Improving Performance and Usability of Homomorphic Encryption
date: 2025-05-08 11:12:00-0400
description: >
  TL;DR: Grafting is a new approach for managing a CKKS ciphertext modulus. With so-called sprouts, we dedicate a few machine words to scaling and use word-sized primes for the remaining ciphertext modulus improving performance. With universal sprouts, we can represent any bit size up to the word size using powers-of-two and introduce arbitrary scaling for RNS-CKKS improving usability for parameter and circuit design.
tags: 
categories: 
related_posts: false
---

- Written by [Johannes Mono](https://www.asdf.one/) (Ruhr University Bochum & CryptoLab)
- Based on [https://ia.cr/2024/1014](https://ia.cr/2024/1014)

_TL;DR: Grafting is a new approach for managing a CKKS ciphertext modulus. With so-called sprouts, we dedicate a few machine words to scaling and use word-sized primes for the remaining ciphertext modulus improving performance. With universal sprouts, we can represent any bit size up to the word size using powers-of-two and introduce arbitrary scaling for RNS-CKKS improving usability for parameter and circuit design._

---

Homomorphic encryption is one of the most exciting technologies for modern society.
If you've never heard of it, congratulations, you're one of [today's lucky 10,000](https://xkcd.com/1053)!
Here's our FAQ to get you started:
- [What is homomorphic encryption?](#faq-what-is-homomorphic-encryption-)
- [What is CKKS?](#faq-what-is-ckks-)

In recent years, research has continuously improved two significant challenges: performance and usability.
_Grafting_ is a new technique improving performance and usability for the homomorphic encryption scheme CKKS.
Let's try to understand the problems Grafting solves.


## CKKS Parameters

Encryption schemes base their security on mathematically hard problems.
The CKKS scheme bases it on the Learning with Errors over Rings (RLWE) problem.
Sounds complicated?
It is.
Fortunately, we do not need to understand it, we only need to meet one important RLWE parameter: the number $q$, also called _ciphertext modulus_.
CKKS needs a huge ciphertext modulus, it sometimes uses over 3000 bits!
For comparison, we can store the number of atoms in the universe in only 266 bits.
And a single CKKS encryption needs thousands of random numbers from 0 to $q$.
That sounds like lots of bits (and it is), but modern technology actually handles them with ease; even your smartphone can store many CKKS encryptions.
Obviously, there is a catch.
We use CKKS not only to store, but to compute on encryptions.
And computing on thousands of numbers from 0 to $q$ is not cheap, especially because we compute complex mathematical functions.

Despite its costs, CKKS is [reasonably fast on modern machines](https://www.youtube.com/watch?v=Zl1lVxQyj60).
Modern machines operate on 64 bits at once, a so-called machine word.
We want to use as few words as possible for our random numbers: the less words we compute on, the faster we are.
For performance, we split up $q$ into $\ell$ small numbers, each using 64 bits: 

$$ \textstyle q = q_1 \cdot q_2 \cdot q_3 \cdot \ldots \cdot q_\ell = \prod_{i = 1}^\ell q_i \text{.} $$

Each number from 0 to $q$ corresponds to exactly $\ell$ numbers from 0 to $q_i$, one for each $q_i$ (Figure 1).

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/blog/250508_Johannes/1.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    Figure 1: A ciphertext modulus $q$ split up into $\ell = 10$ small numbers, each using 64 bits.
</div>

This concept is also known as residue number system (RNS) and we can switch between one large number (0 to $q$) and $\ell$ small numbers (0 to $q_i$) anytime we want due to the [Chinese Remainder Theorem](https://en.m.wikipedia.org/wiki/Chinese_remainder_theorem).
As with RLWE: We do not need to understand the math behind the RNS to understand Grafting, only what we use it for in CKKS.
CKKS uses the RNS to improve performance, but it also uses it for the so-called scaling.


## CKKS Scaling

CKKS encrypts approximate numbers which are, well, approximations of real numbers.
An example you are probably familiar with is $\pi$: Teachers often approximate it as 3.14 for calculations even though it has infinitely many digits.
In CKKS, we approximate numbers using integers and a scaling factor.
For $3.14$, we need a scaling factor $\Delta = 100$ to store it in an integer: 

$$ 3.14 \cdot s = 3.14 \cdot 100 = 314 \text{.} $$

For $3.14159265$, we need $\Delta = 100,000,000 = 10^8$: 

$$ 3.14159265 \cdot \Delta = 3.14159265 \cdot 10^8 = 314159265 \text{.} $$

Alternatively, we round the scaled value and accept a worse approximation (for example with $s = 100$): 

$$ \lceil 3.14159265 \cdot \Delta\rfloor = \lceil 314.159265 \rfloor = 314 \text{.} $$

The larger the scaling factor, the better our approximation---but the larger our integers and the CKKS parameters we will need to encrypt them.
We can add two scaled numbers $x$ and $y$ and get their scaled sum: 

$$ (\Delta \cdot x) + (\Delta \cdot y) = \Delta \cdot (x + y) \text{.} $$

We can also multiply two scaled numbers 

$$ (\Delta \cdot x) \cdot (\Delta \cdot y) = \Delta \cdot (\Delta \cdot x \cdot y) \text{;} $$ 

however, now we get an additional factor $\Delta$ which we have to remove again.
For unencrypted numbers, we simply divide by $\Delta$ to get the correct result.
For encrypted numbers, it is not that simple.

Division in CKKS uses polynomial approximation, polynomial approximation needs multiplications, multiplications need divisions, divisions need polynomial approximations, polynomial approximations need ...
I think you understand the problem.
Fortunately, we have a trick up our sleeves: Instead of dividing the encrypted numbers by $\Delta$, we remove one of the elements in $q = q_1 \cdot \ldots \cdot q_\ell$ with clever (and slightly complex) mathemathics.
If $q_i \approx \Delta$, removing $q_i$ divides the encrypted numbers by $q_i \approx \Delta$ and we can remove the additional $\Delta$ from a multiplication!
However, we cannot remove $q_i$ forever since $q$ only consists of $\ell$ small numbers.
After $\ell - 1$ multiplications, we are left with only one small number: $q_1$.
Then, we use a process called bootstrapping to go back to our big $q = q_1 \cdot \ldots \cdot q_\ell$.

Scaling imposes another restriction on our $q_i$.
Our accumulated requirements are now as follows:
- Each $q_i$ must be close to the scaling factor $s$ for multiplications to work correctly.
- Each $q_i$ needs to be a prime so we can use the RNS representation for performance.
- Each $q_i$ should use 64 bits (the machine word size) for best performance.

But what if the scaling factor $s$ uses much less than 64 bits?
Then, we waste computational resources: A modern machine always computes on 64 bits, even if we do not use all of them.
And currently, CKKS scaling uses much less than 64 bits wasting precious resources.
Grafting with universal sprouts solves this issue: We can scale by anything we want _and_ choose large $q_i$ to use the full machine word.


## Grafting

The idea behind Grafting is surprisingly simple.
What if we could have one special 64 bit word where we can choose any bit size between 0 and 64?
Then we could scale to any bit size we want.
Example (Figure 2): We are at $330 = 10 + 5 \cdot 64$ bits and want to go to $300 = 44 + 4 * 64$ bits.
We remove one large prime ($330 - 64 = 266$) and replace the special 30 bit word with a special 44 bit word ($266 - 10 + 44 = 300$).

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/blog/250508_Johannes/2.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">
    Figure 2: Removing 30 bits from a ciphertext modulus without Grafting (top) and with Grafting (bottom). We need much less machine words for the same modulus size and still can easily scale by 30 bits.
</div>

Along these lines, we can choose any bit size for $q$ using our special word.
If we remove one bit from it, we scale the encrypted numbers by $s \approx 2$.
Removing two bits from the special word scales the encrypted numbers by $s \approx 4$, removing three bits by $s \approx 8$, and so on.
In some sense, we decouple the scaling that we need for a correct CKKS multiplications from the individual $q_i$.
We call the special machine word a sprout, and we call it a universal sprout if it can have any bit size between 0 and 64.
If you just came here to understand the idea behind Grafting, congratulations, you made it!
That's the idea, nothing more, nothing less.

Of course, reality is more complex (it's always the same, huh): How do we actually realize a universal sprout?
While all the mathematical details are in [our paper](https://eprint.iacr.org/2024/1014), let's try to understand it using much less math.
Remember all the thousands of random numbers from 0 to $q$ I talked about?
They have a specific meaning, they are coefficients of a polynomial with degree $N - 1$: 

$$ a(x) = a_0 + a_1 x + a_2 x^2 + \ldots + a_{N-1} x^{N-1} \text{;} $$

each coefficient $a_i$ is a number from 0 to $q$, each polynomial needs $N$ coefficients, and each ciphertext needs two of these polynomials.
Sometimes, we need to multiply two polynomials and we multiply two polynomials with the so-called number theoretic transform (NTT).
The [Wikipedia article](https://en.wikipedia.org/wiki/Discrete_Fourier_transform_over_a_ring#Number-theoretic_transform) is not very helpful if you're not a mathematician, so let's stick to our approach: We only aim at understanding the consequences the NTT has for our $q_i$, not the math behind it.
For the NTT, we need each $q_i$ to equal $1 \bmod 2 N$.
If you're not familiar with the modulo operation, don't worry, I got you: The important thing for us is that it needs to be larger than $2 N$---and usually, $N$ is already 15--20 bits large.
Hence, each $q_i$ is also at least 15--20 bits or larger.
So how can we get a sprout to represent 0 to 20 bits?

One approach is as follows: We use the powers-of-two $0, 1, 2, 4, 8, \ldots, 2^{20}$ even if we then cannot use the NTT.
And we cannot, but we can employ another trick.
We move the power-of-two polynomials to a polynomial with a helper prime, use the NTT for polynomial multiplication, then go back to the power-of-two.
This works as long as the helper prime is larger than 60 bit which fortunately we have.
That's actually all we need, we have a universal sprout: We use powers-of-two for all bit sizes up to 20 with a helper prime, then use different primes up to 64 bit each.
For $N = 2^{15}$, we reduce the number of $q_i$ from 20 to 12, so almost by 50%, and it results in up to two times better performance!
But, in my personal opinion, that's not the best part of Grafting.
I've said it before, I'll say it again: We decouple the scaling from the individual $q_i$ which makes CKKS much more usable.
Two examples: Designing parameter sets is much easier now, and computing with arbitrary scalings is easier now.
And that's it!
I hope you learned how Grafting improves the performance and usability of CKKS.
안녕히 가세요!


## FAQ: What is homomorphic encryption? {#faq-what-is-homomorphic-encryption-}

Homomorphic encryption is a special type of encryption which enables computations on encrypted data.
You can think about it as locking bits or numbers in a secure box with buttons on the outside that launch operations such as an addition or multiplication.
Homomorphic encryption enables new opportunities: You can encrypt your sensitive data, send it to a third party for expensive computations, and get back the encrypted result without doing any of these computations yourself.
This is like sending the third party your secure box, telling them which buttons to press so you don't have to do it, and afterward getting the box back with the result: Your information stays private even when being computed on.


## FAQ: What is CKKS? {#faq-what-is-ckks-}

CKKS is a homomorphic encryption scheme for approximate numbers.
It was created by Cheon, Kim, Kim, and Song in 2016 and shines in data analysis and modelling.
Real-world data is often approximate (for example measurements such as temperature) and so are the computations on the data (for example weather forecasting).
CKKS trades off an exact result for better performance and is a great choice for encrypted computations on most real-world data.
